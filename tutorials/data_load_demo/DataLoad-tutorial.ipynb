{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f18b2252-9d4c-4e34-a4f4-38f8ea8c6d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from dateutil import rrule\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "class InformerDataset:\n",
    "    def __init__(\n",
    "        self,\n",
    "        forecast_horizon = 192,\n",
    "        data_split = \"train\",\n",
    "        data_stride_len = 1,\n",
    "        task_name = \"forecasting\",\n",
    "        random_seed = 42,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        forecast_horizon : int\n",
    "            Length of the prediction sequence.\n",
    "        data_split : str\n",
    "            Split of the dataset, 'train' or 'test'.\n",
    "        data_stride_len : int\n",
    "            Stride length when generating consecutive\n",
    "            time series windows.\n",
    "        task_name : str\n",
    "            The task that the dataset is used for. One of\n",
    "            'forecasting', or  'imputation'.\n",
    "        random_seed : int\n",
    "            Random seed for reproducibility.\n",
    "        \"\"\"\n",
    "\n",
    "        self.seq_len = 512\n",
    "        self.forecast_horizon = forecast_horizon\n",
    "        self.full_file_path_and_name = \"../../data/ETTh1.csv\"\n",
    "        self.data_split = data_split\n",
    "        self.data_stride_len = data_stride_len\n",
    "        self.task_name = task_name\n",
    "        self.random_seed = random_seed\n",
    "\n",
    "        # Read data\n",
    "        self._read_data()\n",
    "\n",
    "    def _get_borders(self):\n",
    "        n_train = 12 * 30 * 24\n",
    "        n_val = 4 * 30 * 24\n",
    "        n_test = 4 * 30 * 24\n",
    "\n",
    "        train_end = n_train\n",
    "        val_end = n_train + n_val\n",
    "        test_start = val_end - self.seq_len\n",
    "        test_end = test_start + n_test + self.seq_len\n",
    "\n",
    "        train = slice(0, train_end)\n",
    "        test = slice(test_start, test_end)\n",
    "\n",
    "        return train, test\n",
    "\n",
    "    def _read_data(self):\n",
    "        self.scaler = StandardScaler()\n",
    "        df = pd.read_csv(self.full_file_path_and_name)\n",
    "        self.length_timeseries_original = df.shape[0]\n",
    "        self.n_channels = df.shape[1] - 1\n",
    "\n",
    "        df.drop(columns=[\"date\"], inplace=True)\n",
    "        df = df.infer_objects(copy=False).interpolate(method=\"cubic\")\n",
    "\n",
    "        data_splits = self._get_borders()\n",
    "\n",
    "        train_data = df[data_splits[0]]\n",
    "        self.scaler.fit(train_data.values)\n",
    "        df = self.scaler.transform(df.values)\n",
    "\n",
    "        if self.data_split == \"train\":\n",
    "            self.data = df[data_splits[0], :]\n",
    "        elif self.data_split == \"test\":\n",
    "            self.data = df[data_splits[1], :]\n",
    "\n",
    "        self.length_timeseries = self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        seq_start = self.data_stride_len * index\n",
    "        seq_end = seq_start + self.seq_len\n",
    "        input_mask = np.ones(self.seq_len)\n",
    "\n",
    "        if self.task_name == \"forecasting\":\n",
    "            pred_end = seq_end + self.forecast_horizon\n",
    "\n",
    "            if pred_end > self.length_timeseries:\n",
    "                pred_end = self.length_timeseries\n",
    "                seq_end = seq_end - self.forecast_horizon\n",
    "                seq_start = seq_end - self.seq_len\n",
    "\n",
    "            timeseries = self.data[seq_start:seq_end, :].T\n",
    "            forecast = self.data[seq_end:pred_end, :].T\n",
    "\n",
    "            return timeseries, forecast, input_mask\n",
    "\n",
    "        elif self.task_name == \"imputation\":\n",
    "            if seq_end > self.length_timeseries:\n",
    "                seq_end = self.length_timeseries\n",
    "                seq_end = seq_end - self.seq_len\n",
    "\n",
    "            timeseries = self.data[seq_start:seq_end, :].T\n",
    "\n",
    "            return timeseries, input_mask\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.task_name == \"imputation\":\n",
    "            return (self.length_timeseries - self.seq_len) // self.data_stride_len + 1\n",
    "        elif self.task_name == \"forecasting\":\n",
    "            return (\n",
    "                self.length_timeseries - self.seq_len - self.forecast_horizon\n",
    "            ) // self.data_stride_len + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d32026-3784-4120-8cba-65e161eecd4a",
   "metadata": {},
   "source": [
    "# 原始数据读取\n",
    "- 可以发现原始数据维度为：（17420，8）  共有7个channel，17420个采样点，OT是我们的待预测变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "516b266a-248b-40b6-abf1-1e613ac0124f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17420, 8)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17420 entries, 0 to 17419\n",
      "Data columns (total 8 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   date    17420 non-null  object \n",
      " 1   HUFL    17420 non-null  float64\n",
      " 2   HULL    17420 non-null  float64\n",
      " 3   MUFL    17420 non-null  float64\n",
      " 4   MULL    17420 non-null  float64\n",
      " 5   LUFL    17420 non-null  float64\n",
      " 6   LULL    17420 non-null  float64\n",
      " 7   OT      17420 non-null  float64\n",
      "dtypes: float64(7), object(1)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data_file = \"../../data/ETTh1.csv\"\n",
    "data = pd.read_csv(data_file)\n",
    "print(data.shape)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a61009e-6aec-4dc1-aa13-4acb3151efb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最小日期值: 2016-07-01 00:00:00\n",
      "最大日期值: 2018-06-26 19:00:00\n",
      "月份差: 24\n"
     ]
    }
   ],
   "source": [
    "# 获取最小日期值\n",
    "min_date = data['date'].min()\n",
    "\n",
    "# 获取最大日期值\n",
    "max_date = data['date'].max()\n",
    "\n",
    "print('最小日期值:', min_date)\n",
    "print('最大日期值:', max_date)\n",
    "# （1）先将字符串-->时间格式date\n",
    "date1 = dt.datetime.strptime(max_date, '%Y-%m-%d %H:%M:%S').date()  ##datetime.date(2018, 1, 6)\n",
    "date2 = dt.datetime.strptime(min_date, '%Y-%m-%d %H:%M:%S').date()  ##datetime.date(2018, 1, 9)\n",
    "# （2）计算两个日期date的天数差\n",
    "Days = (date1 - date2).days\n",
    "Months = rrule.rrule(rrule.MONTHLY, dtstart = date2, until = date1).count()  \n",
    "print('月份差:',Months)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fbceb5-c417-4fb5-9e5e-bfd57fe9c1ab",
   "metadata": {},
   "source": [
    "# 数据集切分\n",
    "- 我们希望输入模型的维度是（batch,channel, seq_len)\n",
    "- 对于（17420，8）的序列，第一个构造的应该是（512，8）axis=0的索引从0到512. 总共原论文中筛选了14400个数据\n",
    "1. n_train = 12 * 30 * 24  取12个月，每月30天，每天24小时\n",
    "2. n_val = 4 * 30 * 24     取4个月，每月30天，每天24小时\n",
    "3. n_test = 4 * 30 * 24    取4个月，每月30天，每天24小时24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e623d48-c290-4f83-b0a3-4c21a881997d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slice(0, 8640, None)\n",
      "slice(11008, 14400, None)\n"
     ]
    }
   ],
   "source": [
    "seq_len = 512\n",
    "n_train = 12 * 30 * 24\n",
    "n_val = 4 * 30 * 24\n",
    "n_test = 4 * 30 * 24\n",
    "train_end = n_train\n",
    "val_end = n_train + n_val\n",
    "test_start = val_end - seq_len\n",
    "test_end = test_start + n_test + seq_len\n",
    "train = slice(0, train_end)\n",
    "test = slice(test_start, test_end)\n",
    "print(train)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0b09d3be-22e8-4b45-93e5-1181f9e102b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_borders(data):\n",
    "    seq_len = 512\n",
    "    n_train = 12 * 30 * 24\n",
    "    n_val = 4 * 30 * 24\n",
    "    n_test = 4 * 30 * 24\n",
    "\n",
    "    train_end = n_train\n",
    "    val_end = n_train + n_val\n",
    "    test_start = val_end - seq_len\n",
    "    test_end = test_start + n_test + seq_len\n",
    "    \n",
    "    train = data.iloc[:train_end]\n",
    "    test = data.iloc[test_start:test_end]\n",
    "    # train = data.slice(0, train_end)\n",
    "    # test = data.slice(test_start, test_end)\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cdce27-e5cc-4ff0-a866-57ef65340a7a",
   "metadata": {},
   "source": [
    "# 数据集读取、预处理\n",
    "- drop掉不要的列，进行异常值填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0aa73d27-2cce-409b-8b53-d2b00bc58d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=[\"date\"], inplace=True)\n",
    "data = data.infer_objects(copy=False).interpolate(method=\"cubic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "be6fdf14-f235-415e-bc1e-a2280c775b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17420 entries, 0 to 17419\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   HUFL    17420 non-null  float64\n",
      " 1   HULL    17420 non-null  float64\n",
      " 2   MUFL    17420 non-null  float64\n",
      " 3   MULL    17420 non-null  float64\n",
      " 4   LUFL    17420 non-null  float64\n",
      " 5   LULL    17420 non-null  float64\n",
      " 6   OT      17420 non-null  float64\n",
      "dtypes: float64(7)\n",
      "memory usage: 952.8 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aeacc4a-8e2d-4478-b1d3-5029eff5a4dd",
   "metadata": {},
   "source": [
    "- 拆分数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "69894ea0-7837-4199-a943-1c7851ecc86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train数据shape: (8640, 7)\n",
      "test数据shape: (3392, 7)\n"
     ]
    }
   ],
   "source": [
    "data_splits = get_borders(data)\n",
    "train_data = data_splits[0]\n",
    "test_data = data_splits[1]\n",
    "print('train数据shape:',train_data.shape)\n",
    "print('test数据shape:',test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e1fff22a-8499-418d-8103-1b59a555005d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scala = StandardScaler()\n",
    "scala.fit(train_data.values)\n",
    "df = scala.transform(data.values) # 根据training set 去标准化数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9ecc9877-16a6-4c96-9ab0-fb5a75c77fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df[data_splits[0].index, :]\n",
    "length_timeseries = train_data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfe2b12-7069-49f6-943a-437c654c253a",
   "metadata": {},
   "source": [
    "# 进行input，forcast，input_mask拆分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "819fd07c-450f-49f9-9a25-9057d570e434",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stride_len = 1 #  Stride length when generating consecutive time series windows.\n",
    "index = 0\n",
    "forecast_horizon = 192  # Length of the prediction sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5b1a10bd-853f-4a40-88a1-8d2f0f18e3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512,)\n"
     ]
    }
   ],
   "source": [
    "seq_start = data_stride_len * index\n",
    "seq_end = seq_start + seq_len\n",
    "input_mask = np.ones(seq_len)\n",
    "print(input_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "24b79d8b-c430-414f-995d-bf4f5ee89708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造pred数据\n",
    "pred_end = seq_end + forecast_horizon\n",
    "if pred_end > length_timeseries:\n",
    "    pred_end = length_timeseries\n",
    "    seq_end = seq_end - forecast_horizon\n",
    "    seq_start = seq_end - seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe73c7a-85a6-45ab-9f16-776303f2c105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _read_data(self):\n",
    "        self.scaler = StandardScaler()\n",
    "        df = pd.read_csv(self.full_file_path_and_name)\n",
    "        self.length_timeseries_original = df.shape[0]\n",
    "        self.n_channels = df.shape[1] - 1\n",
    "\n",
    "        df.drop(columns=[\"date\"], inplace=True)\n",
    "        df = df.infer_objects(copy=False).interpolate(method=\"cubic\")\n",
    "\n",
    "        data_splits = self._get_borders()\n",
    "\n",
    "        train_data = df[data_splits[0]]\n",
    "        self.scaler.fit(train_data.values)\n",
    "        df = self.scaler.transform(df.values)\n",
    "\n",
    "        if self.data_split == \"train\":\n",
    "            self.data = df[data_splits[0], :]\n",
    "        elif self.data_split == \"test\":\n",
    "            self.data = df[data_splits[1], :]\n",
    "\n",
    "        self.length_timeseries = self.data.shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moment",
   "language": "python",
   "name": "moment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
